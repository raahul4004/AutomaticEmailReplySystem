{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "id": "5LW18BnIiYkP"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "import os \n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {
        "id": "kdCacWeLiQL5"
      },
      "outputs": [],
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "GROQ_LLM = ChatGroq(\n",
        "            model=\"llama3-70b-8192\",\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "id": "ZoEDR2FmiGJX"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.output_parsers import JsonOutputParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "id": "jJhoLxciS906"
      },
      "outputs": [],
      "source": [
        "\n",
        "def write_markdown_file(content, filename):\n",
        "  \"\"\"Writes the given content as a markdown file to the local directory.\n",
        "\n",
        "  Args:\n",
        "    content: The string content to write to the file.\n",
        "    filename: The filename to save the file as.\n",
        "  \"\"\"\n",
        "  with open(f\"{filename}.md\", \"w\") as f:\n",
        "    f.write(content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtgPyhgniGLe",
        "outputId": "527baad1-8584-45b0-d724-e4607a815430"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'inquiry_handling'\n"
          ]
        }
      ],
      "source": [
        "#Categorize EMAIL\n",
        "prompt = PromptTemplate(\n",
        "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "    You are a Email Categorizer Agent You are a master at understanding what a customer wants when they write an email and are able to categorize it in a useful way\n",
        "\n",
        "     <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "    Conduct a comprehensive analysis of the email provided and categorize into one of the following categories:\n",
        "        inquiry_handling - used when someone is asking for information about pricing \\\n",
        "        review_handling - used when someone is giving a review, either positive or negative \\\n",
        "        assistance_request_handling - used when someone is asking questions related to issues with equipment \\\\\n",
        "        general_handling when it doesnt relate to any other category \\\n",
        "\n",
        "\n",
        "            Output a single cetgory only from the types ('inquiry_handling', 'review_handling', 'assistance_request_handling', 'general_handling') \\\n",
        "            eg:\n",
        "            'inquiry_handling' \\\n",
        "\n",
        "    EMAIL CONTENT:\\n\\n {initial_email} \\n\\n\n",
        "    <|eot_id|>\n",
        "    <|start_header_id|>assistant<|end_header_id|>\n",
        "    \"\"\",\n",
        "    input_variables=[\"initial_email\"],\n",
        ")\n",
        "\n",
        "email_category_generator = prompt | GROQ_LLM | StrOutputParser()\n",
        "\n",
        "EMAIL = \"\"\"HI there, \\n\n",
        "I am emailing to say that I had a wonderful stay at your resort last week. \\n\n",
        "\n",
        "I really appreaciate what your staff did\n",
        "\n",
        "Thanks,\n",
        "Paul\n",
        "\"\"\"\n",
        "\n",
        "EMAIL = \"\"\"HI there, \\n\n",
        "I am emailing to inquire about the Video camera. \\n\n",
        "\n",
        "Thanks,\n",
        "Paul\n",
        "\"\"\"\n",
        "\n",
        "result = email_category_generator.invoke({\"initial_email\": EMAIL})\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {},
      "outputs": [],
      "source": [
        "# General Handling \n",
        "general_prompt = PromptTemplate(\n",
        "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "    You are an Expert Email Agent, write an email informing the customer that as this issue does not fit in the general categories we will be escalating this to the customer service for further evaluation.\n",
        "     <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "    \n",
        "    EMAIL CONTENT:\\n\\n {initial_email} \\n\\n\n",
        "    EMAIL CATEGORY: \\n\\n {email_category} \\n\\n\n",
        "    <|eot_id|>\n",
        "    <|start_header_id|>assistant<|end_header_id|>\n",
        "    \"\"\",\n",
        ")\n",
        "\n",
        "general_issue_chain = general_prompt | GROQ_LLM | StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {
        "id": "NARt_uo8g9e5"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "from email.mime.text import MIMEText\n",
        "from langchain_community.embeddings.sentence_transformer import (\n",
        "    SentenceTransformerEmbeddings,\n",
        ")\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_chroma.vectorstores import Chroma\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import os\n",
        "\n",
        "current_dir = os.path.dirname(os.path.abspath(\"/content\"))\n",
        "persistent_directory = os.path.join(current_dir, \"data\", \"chroma_db_fe\")\n",
        "\n",
        "# Function to check availability and get price\n",
        "def check_item_availability(item_name):\n",
        "    conn = sqlite3.connect('data/film_equipment.db')  # Replace with your database connection details\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # Query for the requested item\n",
        "    cursor.execute(\"SELECT name, price FROM equipment WHERE name=?\", (item_name,))\n",
        "    result = cursor.fetchone()\n",
        "\n",
        "    if result:\n",
        "        item_price = result[1]\n",
        "        return True, f\"The item '{item_name}' is available at a price of ${item_price:.2f}.\"\n",
        "    else:\n",
        "        # Suggest similar items\n",
        "        cursor.execute(\"SELECT equipment_id, name, type, brand, price FROM equipment\")\n",
        "        items = cursor.fetchall()\n",
        "        item_texts = \"\"\n",
        "        for item in items:\n",
        "            item_texts += f\"{item[1]} {item[2]} {item[3]} \\n \"\n",
        "        f = open(\"data/items.txt\", \"w\")\n",
        "        f.write(item_texts)\n",
        "        f.close()\n",
        "        return False, items\n",
        "\n",
        "\n",
        "# Function to search for similar items using LangChain and ChromaDB\n",
        "def find_similar_items(item_name, items):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=50, chunk_overlap=20)\n",
        "    embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "    if not os.path.exists(persistent_directory):\n",
        "        loader = TextLoader(\"data/items.txt\")\n",
        "        documents = loader.load()\n",
        "        docs = text_splitter.split_documents(documents)\n",
        "\n",
        "        vectorstore = Chroma.from_documents(docs, embeddings, persist_directory=persistent_directory)\n",
        "\n",
        "    else:\n",
        "        vectorstore = Chroma(persist_directory=persistent_directory, embedding_function=embeddings)\n",
        "\n",
        "    # query_vector = embeddings.embed_query(item_name)\n",
        "\n",
        "    results = vectorstore.similarity_search(item_name, k=5)\n",
        "    suggestions = f\"Sorry, the item '{item_name}' is not available. However, you might be interested in these similar items:\\n\"\n",
        "    for i in range(len(results) - 1):\n",
        "        suggestions += results[i].page_content + \"\\n\"\n",
        "    return suggestions\n",
        "\n",
        "def handle_inquiry(item_name):\n",
        "    \n",
        "    is_available, result = check_item_availability(item_name)\n",
        "\n",
        "    if is_available:\n",
        "        response = result\n",
        "    else:\n",
        "        response = find_similar_items(item_name, result)\n",
        "\n",
        "    return response\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXTN3LlzPv2V",
        "outputId": "dd9dd819-a534-4423-e605-363480c96a9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'Video camera'\n"
          ]
        }
      ],
      "source": [
        "## Search keywords\n",
        "search_keyword_prompt = PromptTemplate(\n",
        "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "    You are a master at identifying the film equipments to search for in a database to get the best info for the customer.\n",
        "\n",
        "    given the INITIAL_EMAIL and EMAIL_CATEGORY. Extract the film equipments which are in the email.\n",
        "\n",
        "    Return just the film equipment found in the email.\n",
        "\n",
        "    eg:\n",
        "        'Video camera',\n",
        "        'Camera\n",
        "\n",
        "    <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "    INITIAL_EMAIL: {initial_email} \\n\n",
        "    EMAIL_CATEGORY: {email_category} \\n\n",
        "    <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
        "    input_variables=[\"initial_email\",\"email_category\"],\n",
        ")\n",
        "\n",
        "search_keyword_chain = search_keyword_prompt | GROQ_LLM | StrOutputParser()\n",
        "\n",
        "email_category = 'inquiry_handling'\n",
        "research_info = None\n",
        "\n",
        "print(search_keyword_chain.invoke({\"initial_email\": EMAIL, \"email_category\":email_category}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "T4cATGvMiXVG",
        "outputId": "ddfda889-7d45-48a6-d4d5-e9abb5b854f9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\raahu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sorry, the item ''Video camera'' is not available. However, you might be interested in these similar items:\n",
            "Updated Camera Video Canon \n",
            " Camera Digital Canon\n",
            "Cage Camera SmallRig\n",
            "Cage Camera SmallRig\n",
            "Wireless Video Transmission Teradek\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "inquiry_handler = search_keyword_chain | handle_inquiry \n",
        "\n",
        "email_category = 'customer_feedback'\n",
        "\n",
        "print(inquiry_handler.invoke({\"initial_email\": EMAIL, \"email_category\":email_category}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4jPw1NdkZfd",
        "outputId": "0eedfe2f-58eb-427c-a5de-7eb902f1fb77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dear Paul,\n",
            "\n",
            "Thank you so much for taking the time to share your wonderful experience at our resort! We're thrilled to hear that our staff made a positive impact on your stay. \n",
            "\n",
            "We're grateful for customers like you and would love to hear more about your experience. Please consider sharing your review on social media to help others discover the great service we provide.\n",
            "\n",
            "Once again, thank you for your kind words, and we look forward to welcoming you back soon!\n",
            "\n",
            "Best regards,\n",
            "[Your Name]\n"
          ]
        }
      ],
      "source": [
        "review_handler_prompt = PromptTemplate(\n",
        "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "    You are an expert at reading the initial email and classify whether the review is positive or negative. If the reivew is positive then Thank the sender and encourage them to share their experience on social media. And if the review is negative then  Escalate to the CRM system for follow-up with a phone call from customer service and offer a gift voucher in the reply.\\n\n",
        "\n",
        "    <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "    Email to route INITIAL_EMAIL : {initial_email} \\n\n",
        "    EMAIL_CATEGORY: {email_category} \\n\n",
        "    <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
        "    input_variables=[\"initial_email\",\"email_category\"],\n",
        ")\n",
        "review_handler_chain = review_handler_prompt | GROQ_LLM | StrOutputParser()\n",
        "\n",
        "EMAIL = \"\"\"HI there, \\n\n",
        "I am emailing to say that I had a wonderful stay at your resort last week. \\n\n",
        "\n",
        "I really appreaciate what your staff did\n",
        "\n",
        "Thanks,\n",
        "Paul\n",
        "\"\"\"\n",
        "email_category = 'review_handling'\n",
        "research_info = None\n",
        "\n",
        "print(review_handler_chain.invoke({\"initial_email\": EMAIL, \"email_category\":email_category}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\raahu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Finished Creating embeddings ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\raahu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:784: UserWarning: Relevance scores must be between 0 and 1, got [(Document(metadata={'source': 'C:\\\\Users\\\\raahu\\\\OneDrive\\\\Documents\\\\_Workspace\\\\YOLO\\\\AutomaticEmailReplySystem\\\\src\\\\data\\\\fe_faq.txt'}, page_content='What is a wide-angle lens?\\n\\n    A wide-angle lens has a short focal length, typically 35mm or less, allowing you to capture a broader field of view.\\n\\nWhat is a telephoto lens?\\n\\n    A telephoto lens has a long focal length, typically 70mm or more, allowing you to capture distant subjects with magnification.\\n\\nWhat is the best lens for shooting landscapes?\\n\\n    Wide-angle lenses, such as a 16-35mm, are ideal for capturing expansive landscapes.\\n\\nWhat is the best lens for shooting portraits?\\n\\n    A 50mm or 85mm prime lens with a wide aperture (f/1.4 or f/1.8) is great for portrait photography.\\n\\nWhat is the best lens for shooting action scenes?\\n\\n    A fast zoom lens, such as a 70-200mm f/2.8, is ideal for capturing dynamic action scenes.\\n\\nHow do I use a tripod effectively?\\n\\n    Ensure the tripod is stable and level, use a remote shutter release to avoid camera shake, and adjust the tripod height to achieve the desired composition.\\n\\nWhat is the best tripod for filmmaking?'), -0.1436795134109825), (Document(metadata={'source': 'C:\\\\Users\\\\raahu\\\\OneDrive\\\\Documents\\\\_Workspace\\\\YOLO\\\\AutomaticEmailReplySystem\\\\src\\\\data\\\\fe_faq.txt'}, page_content=\"FAQ on Film Equipment\\n\\nQ1: What types of cameras are used in filmmaking?\\nA1: Filmmaking commonly uses digital cinema cameras, DSLRs, mirrorless cameras, and traditional film cameras. Digital cinema cameras like the ARRI Alexa, RED cameras, and Sony's CineAlta series are popular for their high-resolution capabilities and dynamic range.\\n\\nQ2: What is the difference between a prime lens and a zoom lens?\\nA2: A prime lens has a fixed focal length, which typically results in higher image quality, larger apertures, and better low-light performance. A zoom lens has a variable focal length, allowing for more flexibility in framing shots without changing lenses.\\n\\nQ3: Why is lighting important in filmmaking?\\nA3: Lighting is crucial in filmmaking as it sets the mood, directs attention, and creates depth and texture in the scene. Proper lighting can enhance the visual storytelling and ensure that the subjects are clearly visible and aesthetically pleasing.\"), -0.14480997976562726), (Document(metadata={'source': 'C:\\\\Users\\\\raahu\\\\OneDrive\\\\Documents\\\\_Workspace\\\\YOLO\\\\AutomaticEmailReplySystem\\\\src\\\\data\\\\fe_faq.txt'}, page_content=\"A dolly is a platform on wheels that allows the camera to move smoothly along a track, creating dynamic and controlled camera movements.\\n\\nWhat is a Steadicam and how do I use it?\\n\\n    A Steadicam is a camera stabilization system that allows for smooth handheld shooting. It uses counterweights and gimbals to stabilize the camera.\\n\\nWhat is a crane and how do I use it?\\n\\n    A crane is a large piece of equipment that allows the camera to move through space in three dimensions. It's used for high, sweeping shots and complex camera moves.\\n\\nHow do I choose the right lighting for my film?\\n\\n    Consider the mood and tone of your film, the color temperature of your lights, and the types of lighting equipment available, such as softboxes, LED panels, and Fresnel lights.\\n\\nWhat is three-point lighting?\\n\\n    Three-point lighting is a technique that uses three light sources: key light (main light), fill light (to reduce shadows), and back light (to separate the subject from the background).\"), -0.177979205958684)]\n",
            "  warnings.warn(\n",
            "c:\\Users\\raahu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.05\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
        "from langchain import hub\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_chroma.vectorstores import Chroma\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "\n",
        "def get_vector_store():\n",
        "    # Define the directory containing the text file and the persistent directory\n",
        "    current_dir = os.path.dirname(os.path.abspath(\"C:/Users/raahu/OneDrive/Documents/_Workspace/YOLO/AutomaticEmailReplySystem/src/AutomaticEmailGeneration.ipynb\"))\n",
        "    file_path = os.path.join(current_dir, \"data\", \"fe_faq.txt\")\n",
        "    persistent_directory = os.path.join(current_dir, \"data\", \"chroma_db_faq\")\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "    print(\"\\n--- Finished Creating embeddings ---\")\n",
        "\n",
        "    if not os.path.exists(persistent_directory):\n",
        "        print(\"Persistent directory does not exist, Initializing vector store\")\n",
        "        if not os.path.exists(file_path):\n",
        "            raise FileNotFoundError(\n",
        "                f\"The file {file_path} does not exist. Please check the path. \"\n",
        "            )\n",
        "        loader = TextLoader(file_path)\n",
        "        documents = loader.load()\n",
        "\n",
        "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
        "        docs = text_splitter.split_documents(documents)\n",
        "        print(\"\\n--- Document splitting done ---\")\n",
        "\n",
        "        vectorstore = Chroma.from_documents(\n",
        "            docs, embeddings, persist_directory=persistent_directory\n",
        "        )\n",
        "        print(\"\\n--- Finished Creating a Vector Store ---\")\n",
        "\n",
        "    else:\n",
        "        vectorstore = Chroma(embedding_function=embeddings, persist_directory=persistent_directory)\n",
        "\n",
        "    return vectorstore\n",
        "\n",
        "\n",
        "vectorstore = get_vector_store()\n",
        "retriever = vectorstore.as_retriever(\n",
        "search_type=\"similarity_score_threshold\",\n",
        "search_kwargs={\"k\": 3, \"score_threshold\": 0.05}\n",
        ")\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "\n",
        "rag_prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "# Create the RAG chain using the pipe operator\n",
        "rag_chain = (\n",
        "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "        | rag_prompt\n",
        "        | GROQ_LLM\n",
        "        | StrOutputParser()\n",
        ")\n",
        "\n",
        "# Execute the chain\n",
        "response = rag_chain.invoke(\"I have an issue with the camera\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {
        "id": "j-bsrrckiGRU"
      },
      "outputs": [],
      "source": [
        "from langchain.schema import Document\n",
        "from langgraph.graph import END, StateGraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {
        "id": "YJ77ZCzkiGTL"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import TypedDict\n",
        "from typing import List\n",
        "\n",
        "### State\n",
        "\n",
        "class GraphState(TypedDict):\n",
        "    \"\"\"\n",
        "    Represents the state of our graph.\n",
        "\n",
        "    Attributes:\n",
        "        initial_email: email\n",
        "        email_category: email category\n",
        "        draft_email: LLM generation\n",
        "        final_email: LLM generation\n",
        "        research_info: list of documents\n",
        "        info_needed: whether to add search info\n",
        "        num_steps: number of steps\n",
        "    \"\"\"\n",
        "    initial_email : str\n",
        "    email_category : str\n",
        "    response_: str\n",
        "    num_steps : int"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {
        "id": "bkBcnG2EiGVF"
      },
      "outputs": [],
      "source": [
        "def categorize_email(state):\n",
        "    \"\"\"take the initial email and categorize it\"\"\"\n",
        "    print(\"---CATEGORIZING INITIAL EMAIL---\")\n",
        "    initial_email = state['initial_email']\n",
        "    num_steps = int(state['num_steps'])\n",
        "    num_steps += 1\n",
        "\n",
        "    email_category = email_category_generator.invoke({\"initial_email\": initial_email})\n",
        "    print(email_category)\n",
        "    # save to local disk\n",
        "    write_markdown_file(email_category, \"email_category\")\n",
        "\n",
        "    return {\"email_category\": email_category, \"num_steps\":num_steps}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {},
      "outputs": [],
      "source": [
        "def email_handling(state):\n",
        "    initial_email = state[\"initial_email\"]\n",
        "    email_category = state[\"email_category\"]\n",
        "    num_steps = state['num_steps']\n",
        "    num_steps += 1\n",
        "\n",
        "    if email_category == \"inquiry_handling\":\n",
        "        response_ = inquiry_handler.invoke({\"initial_email\":initial_email, \"email_category\":email_category})\n",
        "        write_markdown_file(response_ , \"response_\")\n",
        "    \n",
        "    elif email_category == \"review_handling\":\n",
        "        response_ = review_handler_chain.invoke({\"initial_email\": initial_email, \"email_category\": email_category})\n",
        "        write_markdown_file(response_, \"response_\")\n",
        "\n",
        "    elif email_category == \"assistance_request_handling\":\n",
        "        response_ = rag_chain.invoke(initial_email)\n",
        "        write_markdown_file(response_, \"response_\")\n",
        "    \n",
        "    else:\n",
        "        response_ = general_issue_chain.invoke({\"initial_email\": initial_email, \"email_category\": email_category})\n",
        "        write_markdown_file(response_, \"response_\")\n",
        "\n",
        "\n",
        "    return {\"response_\": response_, \"num_steps\":num_steps}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {
        "id": "ZXBsR83liGW4"
      },
      "outputs": [],
      "source": [
        "def state_printer(state):\n",
        "    \"\"\"print the state\"\"\"\n",
        "    print(\"---STATE PRINTER---\")\n",
        "    print(f\"Initial Email: {state['initial_email']} \\n\" )\n",
        "    print(f\"Email Category: {state['email_category']} \\n\")\n",
        "    print(f\"Response : {state['response_']} \\n\")\n",
        "    print(f\"Num Steps: {state['num_steps']} \\n\")\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {},
      "outputs": [],
      "source": [
        "workflow = StateGraph(GraphState)\n",
        "# Define the nodes\n",
        "workflow.add_node(\"categorize_email\", categorize_email)\n",
        "workflow.add_node(\"email_handling\", email_handling)  \n",
        "workflow.add_node(\"state_printer\", state_printer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {
        "id": "AN-F6D5niGch"
      },
      "outputs": [],
      "source": [
        "workflow.add_edge(\"categorize_email\", \"email_handling\")\n",
        "workflow.add_edge(\"email_handling\", \"state_printer\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBjEd8sypRLE"
      },
      "source": [
        "### Add Edges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {
        "id": "uZ0p0gOViGed"
      },
      "outputs": [],
      "source": [
        "workflow.set_entry_point(\"categorize_email\")\n",
        "\n",
        "\n",
        "workflow.add_edge(\"state_printer\", END)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {
        "id": "gUZj-DKFiGgh"
      },
      "outputs": [],
      "source": [
        "# Compile\n",
        "app = workflow.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "metadata": {
        "id": "YrQ-4T5NrlTS"
      },
      "outputs": [],
      "source": [
        "# EMAIL = \"\"\"HI there, \\n\n",
        "# I am emailing to find out the current price of Bitcoin. \\n\n",
        "\n",
        "# Can you please help me/\n",
        "\n",
        "# Thanks,\n",
        "# John\n",
        "# \"\"\"\n",
        "\n",
        "# EMAIL = \"\"\"HI there, \\n\n",
        "# I am emailing to say that I had a wonderful stay at your resort last week. \\n\n",
        "\n",
        "# I really appreaciate what your staff did\n",
        "\n",
        "# Thanks,\n",
        "# Paul\n",
        "# \"\"\"\n",
        "\n",
        "# EMAIL = \"\"\"HI there, \\n\n",
        "# I am emailing to say that the resort weather was way to cloudy and overcast. \\n\n",
        "# I wanted to write a song called 'Here comes the sun but it never came'\n",
        "\n",
        "# What should be the weather in Arizona in April?\n",
        "\n",
        "# I really hope you fix this next time.\n",
        "\n",
        "# Thanks,\n",
        "# George\n",
        "# \"\"\"\n",
        "\n",
        "EMAIL = \"\"\"HI there, \\n\n",
        "I have an issue with the Camera\n",
        "\n",
        "Thanks,\n",
        "Ringo\n",
        "\"\"\"\n",
        "\n",
        "# EMAIL = \"\"\"HI there, \\n\n",
        "# Hey I wanna talk about some general issue i Have been facing\n",
        "\n",
        "# Thanks,\n",
        "# Ringo\n",
        "# \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nwwqhqrDxww",
        "outputId": "ba39a758-d9cf-4595-f5fd-773e13bba737"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---CATEGORIZING INITIAL EMAIL---\n",
            "'general_handling'\n",
            "---STATE PRINTER---\n",
            "Initial Email: HI there, \n",
            "\n",
            "Hey I wanna talk about some general issue i Have been facing\n",
            "\n",
            "Thanks,\n",
            "Ringo\n",
            " \n",
            "\n",
            "Email Category: 'general_handling' \n",
            "\n",
            "Response : Here is an email response:\n",
            "\n",
            "Dear Ringo,\n",
            "\n",
            "Thank you for reaching out to us about the general issue you've been experiencing. I appreciate you taking the time to share this with us.\n",
            "\n",
            "After reviewing your concern, I realize that it doesn't fit into our general categories. To ensure you receive the best possible assistance, I'm going to escalate this issue to our Customer Service team for further evaluation.\n",
            "\n",
            "They will review your case and provide a more personalized solution. You can expect a response from them within the next 24-48 hours.\n",
            "\n",
            "Thank you for your patience and cooperation. If you have any further questions or concerns, please don't hesitate to reach out.\n",
            "\n",
            "Best regards,\n",
            "[Your Name]\n",
            "Email Support Agent \n",
            "\n",
            "Num Steps: 2 \n",
            "\n",
            "Here is an email response:\n",
            "\n",
            "Dear Ringo,\n",
            "\n",
            "Thank you for reaching out to us about the general issue you've been experiencing. I appreciate you taking the time to share this with us.\n",
            "\n",
            "After reviewing your concern, I realize that it doesn't fit into our general categories. To ensure you receive the best possible assistance, I'm going to escalate this issue to our Customer Service team for further evaluation.\n",
            "\n",
            "They will review your case and provide a more personalized solution. You can expect a response from them within the next 24-48 hours.\n",
            "\n",
            "Thank you for your patience and cooperation. If you have any further questions or concerns, please don't hesitate to reach out.\n",
            "\n",
            "Best regards,\n",
            "[Your Name]\n",
            "Email Support Agent\n"
          ]
        }
      ],
      "source": [
        "output = app.invoke(inputs)\n",
        "\n",
        "print(output['response_'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
